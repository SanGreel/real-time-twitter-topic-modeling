{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem formulation\n",
    "\n",
    "some text here\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all needed libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically spark\n",
    "import pyspark\n",
    "import operator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "from pyspark.sql.functions import udf, row_number,column\n",
    "\n",
    "# processing\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pyspark.ml.feature import CountVectorizer,StopWordsRemover, HashingTF, IDF, Tokenizer\n",
    "\n",
    "#staff for LDA\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vector as oldVector, Vectors as oldVectors\n",
    "from pyspark.ml.linalg import Vector as newVector, Vectors as newVectors\n",
    "\n",
    "#for debug purpose only\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-3-73ad000ecbc7>:1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-73ad000ecbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m/opt/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    330\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 332\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-3-73ad000ecbc7>:1 "
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User-specific variables**  \n",
    "Please feel free to tweak those variables as you wish. For example, you can set number of last hours to get hottest topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = 'US-NY' #US for USA\n",
    "\n",
    "number_of_hours_to_get_topics = 2\n",
    "\n",
    "# Set window time for interesting\n",
    "frame_start_datetime = \"Sun Jun 27 00:00:00 +0000 2019\"\n",
    "frame_finish_datetime = \"Sun Jun 30 23:00:00 +0000 2019\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Technical variables**  \n",
    "Those variables are needed to connect to db and other technical stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_topics_LDA = 10\n",
    "max_iterations_LDA = 100\n",
    "nomber_of_words_to_for_topic = 15  # number of words per topic\n",
    "\n",
    "historical_tweets_data = './get-tweets-by-geolocation/training_tweets.csv'\n",
    "real_time_tweets_table = \"usa_training_tweets_02_07.training_tweets_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_tweet_to_datetime(frame_datetime):\n",
    "    ts = datetime.strptime(frame_datetime,'%a %b %d %H:%M:%S %z %Y')\n",
    "    return ts\n",
    "\n",
    "def datetime_to_tweet_str(frame_datetime):\n",
    "    #print(type(frame_datetime))\n",
    "    ts = datetime.strftime(frame_datetime, '%a %b %d %H:%M:%S %z %Y')\n",
    "    return ts\n",
    "\n",
    "def tweet2google_timeframe(frame_start_datetime, frame_finish_datetime):\n",
    "    start_date = str_tweet_to_datetime(frame_start_datetime)\n",
    "    end_date = str_tweet_to_datetime(frame_finish_datetime)\n",
    "    tim\n",
    "    \n",
    "def get_google_trends_by_geo(geo):\n",
    "    if geo == 'US':\n",
    "        return google_trends_search_topics_us, google_trends_search_queries_us\n",
    "    elif geo == 'US-NY':\n",
    "        return google_trends_search_topics_us_ny, google_trends_search_queries_us_ny\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move this function to utils\n",
    "def str_rising_to_float(str):\n",
    "    if str is None:\n",
    "        return 0.0\n",
    "    if str == '':\n",
    "        return 0.0\n",
    "    if str == 'Breakout':\n",
    "        return 0.0\n",
    "    \n",
    "    str_value = str.split('%')[0]\n",
    "    if '+' in str_value:\n",
    "        str_value = str_value.split('+')[1]\n",
    "        \n",
    "    if ',' in str_value:\n",
    "        str_value = str_value.replace(',', '.')\n",
    "        value = 1000* float(str_value)\n",
    "        return value\n",
    "    return float(str_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move this function to utils\n",
    "def unique_google_trends_by_time_frame(df):\n",
    "    data = df.collect()\n",
    "    rising_dict = {}\n",
    "    top_dict = {}\n",
    "    \n",
    "    geo = data[0]['geo']\n",
    "    columns = df.columns\n",
    "\n",
    "    for i in range(0, len(data)):\n",
    "        rising_val = data[i][columns[1]]\n",
    "        top_value = data[i][columns[2]]\n",
    "        \n",
    "        if rising_val in rising_dict:\n",
    "            rising_dict[rising_val][0] += str_rising_to_float(data[i][columns[3]])\n",
    "            rising_dict[rising_val][1] += 1\n",
    "        else:\n",
    "            rising_dict[rising_val] = [str_rising_to_float(data[i][columns[3]]), 1]\n",
    "            \n",
    "        if top_value in top_dict:\n",
    "            top_dict[top_value][0] += float(data[i][columns[4]])\n",
    "            top_dict[top_value][1] += 1\n",
    "        else:\n",
    "            top_dict[top_value] = [float(data[i][columns[4]]), 1]\n",
    "    \n",
    "    \n",
    "    for key in top_dict:\n",
    "        top_dict[key] = round(top_dict[key][0] / top_dict[key][1])\n",
    "        \n",
    "    for key in rising_dict:\n",
    "        rising_dict[key] = round(rising_dict[key][0] / rising_dict[key][1])\n",
    "    \n",
    "    top_dict = sorted(top_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    rising_dict = sorted(rising_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    seq = []\n",
    "    len_top = len(top_dict)\n",
    "    len_rising = len(rising_dict)\n",
    "    length = max(len_top, len_rising)\n",
    "    \n",
    "    row = Row(columns[1], columns[2], columns[3], columns[4], columns[5])\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        rising = rising_dict[i][0] if i < len_rising else ''\n",
    "        rising_val = f\"+{rising_dict[i][1]}%\" if i < len_rising else None\n",
    "        \n",
    "        top = top_dict[i][0] if i < len_top else ''\n",
    "        top_val = top_dict[i][1] if i < len_top else None\n",
    "        \n",
    "        seq.append(row(rising, top, rising_val, top_val, geo))\n",
    "    \n",
    "    dframe = spark.createDataFrame(seq)\n",
    "    return dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here should be \"magic IF\" (Yevhen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.csv(historical_tweets_data, inferSchema=True, header=True)\n",
    "df = spark.read.csv('./get-tweets-by-geolocation/data/new_york_training_tweets_15_06.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "['tweet', 'country_code', 'geo_location', 'bounding_box', 'screen_name', 'favourites_count', 'followers_count', 'statuses_count', 'friends_count', 'listed_count', 'user_described_location', 'created_at', 'utc_offset']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tweet', 'string'),\n",
       " ('country_code', 'string'),\n",
       " ('geo_location', 'string'),\n",
       " ('bounding_box', 'string'),\n",
       " ('screen_name', 'string'),\n",
       " ('favourites_count', 'string'),\n",
       " ('followers_count', 'string'),\n",
       " ('statuses_count', 'string'),\n",
       " ('friends_count', 'string'),\n",
       " ('listed_count', 'string'),\n",
       " ('user_described_location', 'string'),\n",
       " ('created_at', 'string'),\n",
       " ('utc_offset', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(df))\n",
    "print(df.columns)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "# Setting an user define function:\n",
    "# This function converts the string cell into a date:\n",
    "func =  udf (lambda x: str_tweet_to_datetime(x), DateType())\n",
    "\n",
    "df = df.withColumn('test', func(col('created_at')))\n",
    "\n",
    "df.dtypes\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tweet', 'string'), ('country_code', 'string'), ('geo_location', 'string'), ('bounding_box', 'string'), ('screen_name', 'string'), ('favourites_count', 'string'), ('followers_count', 'string'), ('statuses_count', 'string'), ('friends_count', 'string'), ('listed_count', 'string'), ('user_described_location', 'string'), ('created_at', 'string'), ('utc_offset', 'string'), ('tweet_data', 'date')]\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o137.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 6, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-14-42b80e770bab>\", line 10, in <lambda>\n  File \"<ipython-input-6-f9d4eed64e56>\", line 2, in str_tweet_to_datetime\nTypeError: strptime() argument 1 must be str, not None\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-14-42b80e770bab>\", line 10, in <lambda>\n  File \"<ipython-input-6-f9d4eed64e56>\", line 2, in str_tweet_to_datetime\nTypeError: strptime() argument 1 must be str, not None\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-42b80e770bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# df.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tweet_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# df1.printSchema()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o137.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 6, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-14-42b80e770bab>\", line 10, in <lambda>\n  File \"<ipython-input-6-f9d4eed64e56>\", line 2, in str_tweet_to_datetime\nTypeError: strptime() argument 1 must be str, not None\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3363)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 345, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 141, in dump_stream\n    for obj in iterator:\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 334, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 83, in <lambda>\n    return lambda *a: toInternal(f(*a))\n  File \"/opt/spark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-14-42b80e770bab>\", line 10, in <lambda>\n  File \"<ipython-input-6-f9d4eed64e56>\", line 2, in str_tweet_to_datetime\nTypeError: strptime() argument 1 must be str, not None\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:836)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "def nothing(x):\n",
    "    return x\n",
    "\n",
    "# Setting an user define function:\n",
    "# This function converts the string cell into a date:\n",
    "func =  udf (lambda x: str_tweet_to_datetime(x), DateType())\n",
    "# func =  udf (lambda x: nothing(x), StringType())\n",
    "\n",
    "df = df.withColumn('tweet_data', func(col('created_at')))\n",
    "\n",
    "print(df.dtypes)\n",
    "# df.show()\n",
    "\n",
    "df.select(\"tweet_data\").show(10, False)\n",
    "\n",
    "# df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to MongoDB for the real-time data\n",
    "**Creating Spark connector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"pipeline\") \\\n",
    "    .config('spark.mongodb.input.uri', 'mongodb://localhost:27017/'+tweets_table) \\\n",
    "    .config('spark.mongodb.output.uri', 'mongodb://localhost:27017/'+tweets_table) \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.3.1') \\\n",
    "    .config('spark.mongodb.input.partitioner', 'MongoPaginateBySizePartitioner') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"recent_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- contributors: null (nullable = true)\n",
      " |-- coordinates: struct (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- display_text_range: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- hashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- urls: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |-- extended_entities: struct (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |-- duration_millis: integer (nullable = true)\n",
      " |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |-- bitrate: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |-- extended_tweet: struct (nullable = true)\n",
      " |    |-- display_text_range: array (nullable = true)\n",
      " |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |-- duration_millis: integer (nullable = true)\n",
      " |    |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- bitrate: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- symbols: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- extended_entities: struct (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |-- duration_millis: integer (nullable = true)\n",
      " |    |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- bitrate: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- full_text: string (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- favorited: boolean (nullable = true)\n",
      " |-- filter_level: string (nullable = true)\n",
      " |-- geo: struct (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      " |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |-- in_reply_to_status_id: long (nullable = true)\n",
      " |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |-- in_reply_to_user_id: long (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- is_quote_status: boolean (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- full_name: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |-- possibly_sensitive: boolean (nullable = true)\n",
      " |-- quote_count: integer (nullable = true)\n",
      " |-- quoted_status: struct (nullable = true)\n",
      " |    |-- contributors: null (nullable = true)\n",
      " |    |-- coordinates: null (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- display_text_range: array (nullable = true)\n",
      " |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |-- extended_entities: struct (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |-- duration_millis: integer (nullable = true)\n",
      " |    |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |-- bitrate: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- extended_tweet: struct (nullable = true)\n",
      " |    |    |-- display_text_range: array (nullable = true)\n",
      " |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- entities: struct (nullable = true)\n",
      " |    |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |    |-- duration_millis: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |-- bitrate: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |-- extended_entities: struct (nullable = true)\n",
      " |    |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |-- additional_media_info: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- description: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- embeddable: boolean (nullable = true)\n",
      " |    |    |    |    |    |    |-- monetizable: boolean (nullable = true)\n",
      " |    |    |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- w: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- h: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- source_user_id: long (nullable = true)\n",
      " |    |    |    |    |    |-- source_user_id_str: string (nullable = true)\n",
      " |    |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |    |    |-- video_info: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- aspect_ratio: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: integer (containsNull = true)\n",
      " |    |    |    |    |    |    |-- duration_millis: integer (nullable = true)\n",
      " |    |    |    |    |    |    |-- variants: array (nullable = true)\n",
      " |    |    |    |    |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |    |    |    |    |-- bitrate: integer (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- content_type: string (nullable = true)\n",
      " |    |    |    |    |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- full_text: string (nullable = true)\n",
      " |    |-- favorite_count: integer (nullable = true)\n",
      " |    |-- favorited: boolean (nullable = true)\n",
      " |    |-- filter_level: string (nullable = true)\n",
      " |    |-- geo: null (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |    |-- in_reply_to_status_id: long (nullable = true)\n",
      " |    |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: long (nullable = true)\n",
      " |    |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |    |-- is_quote_status: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- place: struct (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- place_type: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |-- country_code: string (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |-- possibly_sensitive: boolean (nullable = true)\n",
      " |    |-- quote_count: integer (nullable = true)\n",
      " |    |-- quoted_status_id: long (nullable = true)\n",
      " |    |-- quoted_status_id_str: string (nullable = true)\n",
      " |    |-- reply_count: integer (nullable = true)\n",
      " |    |-- retweet_count: integer (nullable = true)\n",
      " |    |-- retweeted: boolean (nullable = true)\n",
      " |    |-- scopes: struct (nullable = true)\n",
      " |    |    |-- followers: boolean (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- truncated: boolean (nullable = true)\n",
      " |    |-- user: struct (nullable = true)\n",
      " |    |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- favourites_count: integer (nullable = true)\n",
      " |    |    |-- follow_request_sent: null (nullable = true)\n",
      " |    |    |-- followers_count: integer (nullable = true)\n",
      " |    |    |-- following: null (nullable = true)\n",
      " |    |    |-- friends_count: integer (nullable = true)\n",
      " |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- is_translator: boolean (nullable = true)\n",
      " |    |    |-- lang: null (nullable = true)\n",
      " |    |    |-- listed_count: integer (nullable = true)\n",
      " |    |    |-- location: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- notifications: null (nullable = true)\n",
      " |    |    |-- profile_background_color: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_link_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |    |-- profile_text_color: string (nullable = true)\n",
      " |    |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- statuses_count: integer (nullable = true)\n",
      " |    |    |-- time_zone: null (nullable = true)\n",
      " |    |    |-- translator_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- utc_offset: null (nullable = true)\n",
      " |    |    |-- verified: boolean (nullable = true)\n",
      " |-- quoted_status_id: long (nullable = true)\n",
      " |-- quoted_status_id_str: string (nullable = true)\n",
      " |-- quoted_status_permalink: struct (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- expanded: string (nullable = true)\n",
      " |    |-- display: string (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp_ms: string (nullable = true)\n",
      " |-- truncated: boolean (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: integer (nullable = true)\n",
      " |    |-- follow_request_sent: null (nullable = true)\n",
      " |    |-- followers_count: integer (nullable = true)\n",
      " |    |-- following: null (nullable = true)\n",
      " |    |-- friends_count: integer (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: null (nullable = true)\n",
      " |    |-- listed_count: integer (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: null (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: integer (nullable = true)\n",
      " |    |-- time_zone: null (nullable = true)\n",
      " |    |-- translator_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: null (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_data = spark.sql('SELECT text FROM recent_data WHERE lang=\"en\" AND place.country=\"US\" LIMIT 10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|text|\n",
      "+----+\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recent_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here should be Main dataframe already filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_search_queries_us = spark.read.csv('data/google-trends/google-trends-search-queries-US.csv', inferSchema=True, header=True)\n",
    "google_trends_search_topics_us = spark.read.csv('data/google-trends/google-trends-search-topics-US.csv', inferSchema=True, header=True)\n",
    "google_trends_search_queries_us_ny = spark.read.csv('data/google-trends/google-trends-search-queries-US-NY.csv', inferSchema=True, header=True)\n",
    "google_trends_search_topics_us_ny = spark.read.csv('data/google-trends/google-trends-search-topics-US-NY.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description ()\n",
    "In order to collect data in a natural way:\n",
    "<br>- we registered Twitter Developer account;\n",
    "<br>- using credentials from Twitter Developer account we run script that collected tweets by the geolocation and saved them in mongodb;\n",
    "<br>\n",
    "<br><b>As a result:</b>\n",
    "<br>- we collected  332548 tweets (10Gb in mongodb, ~100Mb in csv) from New-York geolocation since 30 of May up to 15 of June;\n",
    "<br>- we collected  6617029 tweets (~1.69Gb in csv) from USA geolocation since 15 of June up to now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "# description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     " frame_start_datetime ": {},
     "-frame_start_datetime-": {},
     "frame_finish_datetime": {}
    }
   },
   "source": [
    "#### Selecting data from {{ frame_start_datetime }} to {{frame_finish_datetime}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`text`' given input columns: [];;\\n'Project ['text]\\n+- Relation[] MongoRelation(MongoRDD[14] at RDD at MongoRDD.scala:51,Some(StructType()))\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o837.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`text`' given input columns: [];;\n'Project ['text]\n+- Relation[] MongoRelation(MongoRDD[14] at RDD at MongoRDD.scala:51,Some(StructType()))\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:110)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:107)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:85)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3406)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1334)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d07b0be454d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mStopWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mStopWords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \"\"\"\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`text`' given input columns: [];;\\n'Project ['text]\\n+- Relation[] MongoRelation(MongoRDD[14] at RDD at MongoRDD.scala:51,Some(StructType()))\\n\""
     ]
    }
   ],
   "source": [
    "StopWords = stopwords.words(\"english\")\n",
    "\n",
    "tokens = df.select('text').rdd \\\n",
    "    .map(lambda x: x[0]) \\\n",
    "    .map( lambda document: re.split(\" \", document))          \\\n",
    "    .map( lambda word: [x for x in word if x.isalpha()])           \\\n",
    "    .map( lambda word: [x for x in word if len(x) > 3] )           \\\n",
    "    .map( lambda word: [x for x in word if x not in StopWords])    \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3224fade73a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "tokens.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling/Latent Dirichlet allocation(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 23:23:25\n",
      "07042019 23:23:25\n"
     ]
    }
   ],
   "source": [
    "# this block can be commented, it's just a mock\n",
    "\n",
    "text_file = 'data/listings.csv'\n",
    "df = spark.read.csv(text_file, inferSchema=True, header=True)\n",
    "df = df.select(\"id\", \"name\").dropna(subset=\"name\")\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"name\", outputCol=\"tokens\")\n",
    "df = tokenizer.transform(df)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 23:23:25\n",
      "07042019 23:23:26\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"raw_features\", vocabSize=5000, minDF=3.0)\n",
    "cvmodel = cv.fit(df)\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 23:23:26\n",
      "07042019 23:23:26\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "df = cvmodel.transform(df)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tf_idf_features\", minDocFreq=2)\n",
    "idfModel = idf.fit(df)\n",
    "\n",
    "df = idfModel.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|                name|              tokens|        raw_features|     tf_idf_features|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  1|            27987182|          [27987182]|        (1778,[],[])|        (1778,[],[])|\n",
      "|  2|            21686664|          [21686664]|        (1778,[],[])|        (1778,[],[])|\n",
      "|  3|            21686664|          [21686664]|        (1778,[],[])|        (1778,[],[])|\n",
      "|  4|            17607060|          [17607060]|        (1778,[],[])|        (1778,[],[])|\n",
      "|  5|             5630387|           [5630387]|        (1778,[],[])|        (1778,[],[])|\n",
      "|  6|YAYS Bickersgrach...|[yays, bickersgra...|(1778,[265,694,77...|(1778,[265,694,77...|\n",
      "|  7|YAYS Bickersgrach...|[yays, bickersgra...|(1778,[265,694,96...|(1778,[265,694,96...|\n",
      "|  8|Roof Terrace Cozy...|[roof, terrace, c...|(1778,[16,45,62,8...|(1778,[16,45,62,8...|\n",
      "|  9|Amazing APT next ...|[amazing, apt, ne...|(1778,[13,14,32,5...|(1778,[13,14,32,5...|\n",
      "| 10|YAYS Oostenburger...|[yays, oostenburg...|(1778,[26,28,694,...|(1778,[26,28,694,...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(\"name\")\n",
    "#df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().orderBy(column(\"id\"))\n",
    "df = df.withColumn(\"id\", row_number().over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = df.rdd.map(lambda x: (x[0], oldVectors.fromML(x[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|_1 |_2                                                                                                                                          |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |(1778,[],[])                                                                                                                                |\n",
      "|2  |(1778,[],[])                                                                                                                                |\n",
      "|3  |(1778,[],[])                                                                                                                                |\n",
      "|4  |(1778,[],[])                                                                                                                                |\n",
      "|5  |(1778,[],[])                                                                                                                                |\n",
      "|6  |(1778,[265,694,772,969],[6.1138879623208675,7.47719280521606,7.572502985020384,7.929177928959117])                                          |\n",
      "|7  |(1778,[265,694,969,1060],[6.1138879623208675,7.47719280521606,7.929177928959117,8.083328608786376])                                         |\n",
      "|8  |(1778,[16,45,62,84],[2.803514713802898,3.5069008916639377,3.932288702887729,4.337753810995894])                                             |\n",
      "|9  |(1778,[13,14,32,58,72,335],[5.266011437514937,2.7212542764355874,3.2752175788015934,3.8638209036102684,4.046142460404223,6.409352175214703])|\n",
      "|10 |(1778,[26,28,694,723],[3.0409793392005917,3.2365202888479097,7.47719280521606,7.572502985020384])                                           |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs_df = rs.toDF()\n",
    "rs_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 23:27:34\n",
      "07042019 23:28:31\n"
     ]
    }
   ],
   "source": [
    "# Run the LDA Topic Modeler\n",
    "# Note the time before and after is printed in order to find out how much time it takes to process x number of records\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "lda_model = LDA.train(rs_df['_1', '_2'].rdd.map(list), k=num_of_topics_LDA, maxIterations=max_iterations_LDA)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 23:29:31\n",
      "07042019 23:29:32\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "topics = lda_model.topicsMatrix()\n",
    "vocabArray = cvmodel.vocabulary\n",
    "\n",
    "topicIndices = sc.parallelize(lda_model.describeTopics(maxTermsPerTopic = wordNumbers))\n",
    "\n",
    "def topic_render(topic):  # specify vector id of words to actual words\n",
    "    terms = topic[0]\n",
    "    prob = topic[1]\n",
    "    \n",
    "    result = []\n",
    "    for i in range(nomber_of_words_to_for_topic):\n",
    "        term = str(round(prob[i],3))+\"  \"+vocabArray[terms[i]]\n",
    "        result.append(term)\n",
    "    return result\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 23:29:33\n",
      "07042019 23:29:33\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "topics_final = topicIndices.map(lambda topic:topic_render(topic)).collect()\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1\n",
      "0.057  for\n",
      "0.055  apartment\n",
      "0.045  in\n",
      "0.036  a\n",
      "0.036  bedroom\n",
      "0.031  2\n",
      "0.027  with\n",
      "0.025  amsterdam\n",
      "0.016  canal\n",
      "0.014  room\n",
      "0.014  of\n",
      "0.013  view\n",
      "0.012  the\n",
      "0.011  1\n",
      "0.011  house\n",
      "\n",
      "\n",
      "Topic #2\n",
      "0.077  apartment\n",
      "0.066  in\n",
      "0.042  amsterdam\n",
      "0.027  with\n",
      "0.022  spacious\n",
      "0.022  and\n",
      "0.018  near\n",
      "0.017  &\n",
      "0.015  the\n",
      "0.015  city\n",
      "0.013  garden\n",
      "0.012  cosy\n",
      "0.012  room\n",
      "0.012  cozy\n",
      "0.012  bright\n",
      "\n",
      "\n",
      "Topic #3\n",
      "0.07  apartment\n",
      "0.056  with\n",
      "0.048  in\n",
      "0.028  amsterdam\n",
      "0.026  spacious\n",
      "0.019  garden\n",
      "0.018  and\n",
      "0.017  the\n",
      "0.017  &\n",
      "0.017  house\n",
      "0.015  near\n",
      "0.014  city\n",
      "0.013  modern\n",
      "0.012  family\n",
      "0.012  terrace\n",
      "\n",
      "\n",
      "Topic #4\n",
      "0.07  apartment\n",
      "0.062  in\n",
      "0.039  amsterdam\n",
      "0.03  with\n",
      "0.022  spacious\n",
      "0.022  &\n",
      "0.02  the\n",
      "0.019  to\n",
      "0.017  house\n",
      "0.016  room\n",
      "0.016  and\n",
      "0.016  city\n",
      "0.015  cosy\n",
      "0.014  garden\n",
      "0.013  near\n",
      "\n",
      "\n",
      "Topic #5\n",
      "0.066  apartment\n",
      "0.066  in\n",
      "0.044  amsterdam\n",
      "0.028  the\n",
      "0.027  centre\n",
      "0.027  city\n",
      "0.023  to\n",
      "0.017  with\n",
      "0.016  spacious\n",
      "0.016  near\n",
      "0.016  room\n",
      "0.014  center\n",
      "0.014  of\n",
      "0.013  and\n",
      "0.013  &\n",
      "\n",
      "\n",
      "Topic #6\n",
      "0.075  in\n",
      "0.069  apartment\n",
      "0.041  amsterdam\n",
      "0.034  the\n",
      "0.023  city\n",
      "0.019  room\n",
      "0.018  centre\n",
      "0.017  with\n",
      "0.017  of\n",
      "0.016  near\n",
      "0.015  cosy\n",
      "0.015  spacious\n",
      "0.015  and\n",
      "0.015  &\n",
      "0.014  center\n",
      "\n",
      "\n",
      "Topic #7\n",
      "0.065  apartment\n",
      "0.06  in\n",
      "0.035  amsterdam\n",
      "0.024  with\n",
      "0.023  the\n",
      "0.019  spacious\n",
      "0.017  near\n",
      "0.016  house\n",
      "0.016  city\n",
      "0.015  and\n",
      "0.013  &\n",
      "0.013  2\n",
      "0.013  room\n",
      "0.012  family\n",
      "0.012  cosy\n",
      "\n",
      "\n",
      "Topic #8\n",
      "0.061  apartment\n",
      "0.058  in\n",
      "0.042  amsterdam\n",
      "0.023  city\n",
      "0.022  the\n",
      "0.019  room\n",
      "0.018  with\n",
      "0.018  centre\n",
      "0.017  center\n",
      "0.017  and\n",
      "0.017  spacious\n",
      "0.015  near\n",
      "0.014  to\n",
      "0.014  &\n",
      "0.013  from\n",
      "\n",
      "\n",
      "Topic #9\n",
      "0.057  apartment\n",
      "0.037  in\n",
      "0.027  amsterdam\n",
      "0.025  city\n",
      "0.021  with\n",
      "0.019  |\n",
      "0.019  &\n",
      "0.018  near\n",
      "0.018  and\n",
      "0.018  centre\n",
      "0.018  spacious\n",
      "0.017  to\n",
      "0.016  center\n",
      "0.014  apt\n",
      "0.014  the\n",
      "\n",
      "\n",
      "Topic #10\n",
      "0.069  in\n",
      "0.062  apartment\n",
      "0.038  amsterdam\n",
      "0.026  the\n",
      "0.022  with\n",
      "0.021  room\n",
      "0.02  spacious\n",
      "0.019  and\n",
      "0.018  &\n",
      "0.014  near\n",
      "0.014  house\n",
      "0.013  city\n",
      "0.013  private\n",
      "0.012  cosy\n",
      "0.012  of\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# based on the simple vectors(+number of words)\n",
    "\n",
    "for topic in range(len(topics_final)):\n",
    "    print (\"Topic #\" + str(topic+1) + \"\")\n",
    "    for term in topics_final[topic]:\n",
    "        print (term)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1\n",
      "0.103  house\n",
      "0.081  family\n",
      "0.079  beautiful\n",
      "0.049  on\n",
      "0.044  at\n",
      "0.038  houseboat\n",
      "0.037  amsterdam\n",
      "0.033  new\n",
      "0.033  perfect\n",
      "0.023  two\n",
      "0.014  north\n",
      "0.013  warm\n",
      "0.012  suite\n",
      "0.012  historic\n",
      "0.011  \n",
      "\n",
      "\n",
      "Topic #2\n",
      "0.127  the\n",
      "0.08  of\n",
      "0.055  bedroom\n",
      "0.04  comfortable\n",
      "0.039  luxury\n",
      "0.037  heart\n",
      "0.032  large\n",
      "0.03  free\n",
      "0.028  amsterdam\n",
      "0.028  parking\n",
      "0.024  3\n",
      "0.022  in\n",
      "0.02  1\n",
      "0.02  double\n",
      "0.019  stay\n",
      "\n",
      "\n",
      "Topic #3\n",
      "0.109  with\n",
      "0.085  garden\n",
      "0.067  a\n",
      "0.062  home\n",
      "0.061  for\n",
      "0.051  area\n",
      "0.039  in\n",
      "0.037  east\n",
      "0.036  trendy\n",
      "0.029  apt.\n",
      "0.019  romantic\n",
      "0.016  comfy\n",
      "0.013  area!\n",
      "0.012  apartment\n",
      "0.011  friendly\n",
      "\n",
      "\n",
      "Topic #4\n",
      "0.107  city\n",
      "0.093  centre\n",
      "0.088  to\n",
      "0.082  center\n",
      "0.055  close\n",
      "0.037  next\n",
      "0.035  from\n",
      "0.022  min\n",
      "0.018  park\n",
      "0.017  district\n",
      "0.016  spacious,\n",
      "0.015  centre!\n",
      "0.013  15\n",
      "0.013  10\n",
      "0.013  stunning\n",
      "\n",
      "\n",
      "Topic #5\n",
      "0.096  near\n",
      "0.068  lovely\n",
      "0.067  cozy\n",
      "0.066  cosy\n",
      "0.056  vondelpark\n",
      "0.05  nice\n",
      "0.045  west\n",
      "0.034  appartement\n",
      "0.025  amsterdam\n",
      "0.02  old\n",
      "0.02  clean\n",
      "0.02  apartment\n",
      "0.015  square\n",
      "0.013  amsterdam,\n",
      "0.013  neighbourhood\n",
      "\n",
      "\n",
      "Topic #6\n",
      "0.105  and\n",
      "0.094  spacious\n",
      "0.072  bright\n",
      "0.061  great\n",
      "0.058  light\n",
      "0.044  quiet\n",
      "0.04  location\n",
      "0.037  charming\n",
      "0.027  place\n",
      "0.02  museum\n",
      "0.018  rai\n",
      "0.018  nearby\n",
      "0.017  apartment\n",
      "0.012  neighborhood\n",
      "0.011  en\n",
      "\n",
      "\n",
      "Topic #7\n",
      "0.095  &\n",
      "0.06  |\n",
      "0.057  apt\n",
      "0.049  terrace\n",
      "0.046  jordaan\n",
      "0.042  stylish\n",
      "0.042  +\n",
      "0.039  balcony\n",
      "0.036  roof\n",
      "0.034  loft\n",
      "0.033  amazing\n",
      "0.027  located\n",
      "0.027  westerpark\n",
      "0.025  rooftop\n",
      "0.023  apartment,\n",
      "\n",
      "\n",
      "Topic #8\n",
      "0.08  modern\n",
      "0.074  in\n",
      "0.066  apartment\n",
      "0.06  central\n",
      "0.058  pijp\n",
      "0.055  sunny\n",
      "0.051  de\n",
      "0.05  amsterdam\n",
      "0.025  amstel\n",
      "0.023  hip\n",
      "0.015  by\n",
      "0.015  vibrant\n",
      "0.015  river\n",
      "0.014  garden!\n",
      "0.009  fully\n",
      "\n",
      "\n",
      "Topic #9\n",
      "0.111  room\n",
      "0.083  private\n",
      "0.076  studio\n",
      "0.07  2\n",
      "0.056  -\n",
      "0.026  @\n",
      "0.024  in\n",
      "0.022  flat\n",
      "0.022  amsterdam!\n",
      "0.022  4\n",
      "0.019  authentic\n",
      "0.016  bikes\n",
      "0.015  w/\n",
      "0.015  location!\n",
      "0.012  small\n",
      "\n",
      "\n",
      "Topic #10\n",
      "0.079  canal\n",
      "0.066  appartment\n",
      "0.065  view\n",
      "0.054  apartment\n",
      "0.041  luxurious\n",
      "0.038  \n",
      "0.037  floor\n",
      "0.035  big\n",
      "0.031  renovated\n",
      "0.029  design\n",
      "0.024  top\n",
      "0.023  a'dam\n",
      "0.022  very\n",
      "0.022  ground\n",
      "0.019  with\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#based on the tf-idf\n",
    "\n",
    "for topic in range(len(topics_final)):\n",
    "    print (\"Topic #\" + str(topic+1) + \"\")\n",
    "    for term in topics_final[topic]:\n",
    "        print (term)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot topics in the USA from [Google trends](https://trends.google.com/trends/explore?geo=US)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = str_tweet_to_datetime(frame_start_datetime)\n",
    "finish_date = str_tweet_to_datetime(frame_finish_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_trends_topics, google_trends_queries = get_google_trends_by_geo(geo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google trends topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesing_google_topics = google_trends_topics.filter(\n",
    "    (google_trends_topics.Date >= start_date) & (google_trends_topics.Date <= finish_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------------------------------------------+---------------------------------------+\n",
      "|Date               |Search topics - rising                                       |Search topics - top                    |\n",
      "+-------------------+-------------------------------------------------------------+---------------------------------------+\n",
      "|2019-06-27 00:00:00|Software - Software grouping                                 |New York - City in New York            |\n",
      "|2019-06-27 00:00:00|Academic degree - Degree                                     |New York - US State                    |\n",
      "|2019-06-27 00:00:00|Loan - Topic                                                 |2019 - Topic                           |\n",
      "|2019-06-27 00:00:00|Management - Topic                                           |Hotel - Building function              |\n",
      "|2019-06-27 00:00:00|Bra - Dress                                                  |Weather - Topic                        |\n",
      "|2019-06-27 00:00:00|Nike - Footwear manufacturing company                        |Google Search - Topic                  |\n",
      "|2019-06-27 00:00:00|2016 Democratic Party presidential debates and forums - Topic|Google - Technology company            |\n",
      "|2019-06-27 00:00:00|Democratic Party - United States                             |Facebook, Inc. - Social network company|\n",
      "|2019-06-27 00:00:00|Mortgage loan - Topic                                        |Facebook - Social networking service   |\n",
      "|2019-06-27 00:00:00|Debate - Topic                                               |YouTube - Video sharing company        |\n",
      "|2019-06-27 00:00:00|T-shirt - Clothing                                           |Car - Transportation mode              |\n",
      "|2019-06-27 00:00:00|Hotel - Building function                                    |Film - Topic                           |\n",
      "|2019-06-27 00:00:00|Cosmetics - Topic                                            |Sales - Topic                          |\n",
      "|2019-06-27 00:00:00|System - Topic                                               |Amazon.com - E-commerce company        |\n",
      "|2019-06-27 00:00:00|Business - Topic                                             |Restaurant - Topic                     |\n",
      "+-------------------+-------------------------------------------------------------+---------------------------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interesing_google_topics.select(\"Date\",\"Search topics - rising\", \"Search topics - top\").show(15, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case when timeframe is more than 1 day, filter correctly this google-trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------+------+---+-----+\n",
      "|Search topics - rising| Search topics - top|Rising|Top|  geo|\n",
      "+----------------------+--------------------+------+---+-----+\n",
      "|  Kamala Harris - U...|New York - City i...|+3550%|100|US-NY|\n",
      "|  Marianne Williams...| New York - US State|+2200%| 90|US-NY|\n",
      "|  Brooklyn Nets - B...|        2019 - Topic|+1050%| 42|US-NY|\n",
      "|  United States wom...|     Weather - Topic| +750%| 37|US-NY|\n",
      "|  Pete Buttigieg - ...|Hotel - Building ...| +650%| 28|US-NY|\n",
      "|  Joe Biden - Forme...|Google Search - T...| +600%| 24|US-NY|\n",
      "|  Kevin Durant - Am...|Google - Technolo...| +600%| 24|US-NY|\n",
      "|  Boston Red Sox - ...|YouTube - Video s...| +400%| 24|US-NY|\n",
      "|         Radar - Topic|        Film - Topic| +350%| 24|US-NY|\n",
      "|    Free agent - Topic|Facebook, Inc. - ...| +350%| 23|US-NY|\n",
      "|  Software - Softwa...|Facebook - Social...| +250%| 23|US-NY|\n",
      "|  Academic degree -...|       Sales - Topic| +250%| 20|US-NY|\n",
      "|  FIFA Women's Worl...|United States - C...| +250%| 20|US-NY|\n",
      "|  World Cup - Footb...|  Restaurant - Topic| +250%| 19|US-NY|\n",
      "|  2019 FIFA Women's...|The Weather Chann...| +250%| 19|US-NY|\n",
      "|  France - Country ...|Car - Transportat...| +200%| 18|US-NY|\n",
      "|  Colombia - Countr...|Amazon.com - E-co...| +200%| 18|US-NY|\n",
      "|  LGBT Pride March ...|Brooklyn - New Yo...| +200%| 18|US-NY|\n",
      "|  Copa Amrica - Fo...|   Gay pride - Topic| +180%| 18|US-NY|\n",
      "|  New York Yankees ...|         Food - Food| +180%| 17|US-NY|\n",
      "+----------------------+--------------------+------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interesing_google_topics_unique= unique_google_trends_by_time_frame(interesing_google_topics)\n",
    "interesing_google_topics_unique.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google trends queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesing_google_queries = google_trends_queries.filter(\n",
    "    (google_trends_queries.Date >= start_date) & (google_trends_queries.Date <= finish_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+--------------------+-------+---+-----+\n",
      "|               Date|Search queries - rising|Search queries - top| Rising|Top|  geo|\n",
      "+-------------------+-----------------------+--------------------+-------+---+-----+\n",
      "|2019-06-27 00:00:00|         gerrymandering|                 you|+4,250%|100|US-NY|\n",
      "|2019-06-27 00:00:00|          tulsi gabbard|             weather|+1,850%| 74|US-NY|\n",
      "|2019-06-27 00:00:00|            cory booker|              google|+1,450%| 73|US-NY|\n",
      "|2019-06-27 00:00:00|          julian castro|            facebook|+1,200%| 62|US-NY|\n",
      "|2019-06-27 00:00:00|   india vs west ind...|                news|  +750%| 48|US-NY|\n",
      "|2019-06-27 00:00:00|           john delaney|              amazon|  +450%| 47|US-NY|\n",
      "|2019-06-27 00:00:00|       elizabeth warren|             youtube|  +400%| 45|US-NY|\n",
      "|2019-06-27 00:00:00|              ind vs wi|              debate|  +250%| 36|US-NY|\n",
      "|2019-06-27 00:00:00|              powerball|           world cup|  +250%| 25|US-NY|\n",
      "|2019-06-27 00:00:00|             path train|           instagram|  +150%| 25|US-NY|\n",
      "|2019-06-27 00:00:00|             jay inslee|          craigslist|  +150%| 24|US-NY|\n",
      "|2019-06-27 00:00:00|                 debate|             walmart|  +150%| 22|US-NY|\n",
      "|2019-06-27 00:00:00|                   path|   democratic debate|  +110%| 20|US-NY|\n",
      "|2019-06-27 00:00:00|      democratic debate|               apple|  +110%| 19|US-NY|\n",
      "|2019-06-27 00:00:00|                supreme|                 mlb|   +80%| 18|US-NY|\n",
      "|2019-06-28 00:00:00|          shay mitchell|             weather|+3,700%|100|US-NY|\n",
      "|2019-06-28 00:00:00|    marianne williamson|              google|+2,750%| 84|US-NY|\n",
      "|2019-06-28 00:00:00|          kamala harris|            facebook|+2,400%| 74|US-NY|\n",
      "|2019-06-28 00:00:00|   argentina vs vene...|             youtube|  +900%| 68|US-NY|\n",
      "|2019-06-28 00:00:00|             usa france|           world cup|  +900%| 63|US-NY|\n",
      "+-------------------+-----------------------+--------------------+-------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interesing_google_queries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+------+---+-----+\n",
      "|Search queries - rising|Search queries - top|Rising|Top|  geo|\n",
      "+-----------------------+--------------------+------+---+-----+\n",
      "|                     yy|                 you|+4950%|100|US-NY|\n",
      "|         gerrymandering|             weather|+4250%| 94|US-NY|\n",
      "|          shay mitchell|               pride|+3700%| 62|US-NY|\n",
      "|        darren collison|              google|+2950%| 60|US-NY|\n",
      "|    marianne williamson|            facebook|+2750%| 60|US-NY|\n",
      "|          kamala harris|             youtube|+2400%| 48|US-NY|\n",
      "|         deandre jordan|                news|+2400%| 45|US-NY|\n",
      "|          tulsi gabbard|              amazon|+1850%| 45|US-NY|\n",
      "|            cory booker|           world cup|+1450%| 38|US-NY|\n",
      "|          julian castro|              debate|+1200%| 36|US-NY|\n",
      "|       india vs england|             yankees|+1050%| 34|US-NY|\n",
      "|   argentina vs vene...|        pride parade| +900%| 30|US-NY|\n",
      "|             usa france|               yahoo| +900%| 28|US-NY|\n",
      "|     brazil vs paraguay|                 nba| +900%| 27|US-NY|\n",
      "|          usa vs france|           instagram| +900%| 26|US-NY|\n",
      "|      colombia vs chile|          craigslist| +800%| 26|US-NY|\n",
      "|           kevin durant|        copa america| +800%| 26|US-NY|\n",
      "|   india vs west ind...|                 map| +750%| 25|US-NY|\n",
      "|            alex morgan|             walmart| +750%| 23|US-NY|\n",
      "|         michael bennet|    pride parade nyc| +700%| 23|US-NY|\n",
      "+-----------------------+--------------------+------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interesing_google_queries_unique= unique_google_trends_by_time_frame(interesing_google_queries)\n",
    "interesing_google_queries_unique.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot topics - google trends (directly) (probably this will be removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t   README.md\r\n",
      "get-google-trends-data\t   realtime_twitter_topic_modeling_pyspark.ipynb\r\n",
      "get-tweets-by-geolocation  sample_lda_data.txt\r\n",
      "LICENSE\t\t\t   spark_LDA.ipynb\r\n",
      "python-data-preprocessing  spark_LDA_v2.ipynb\r\n",
      "python_LDA.ipynb\t   spark-warehouse\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_google_trends_data.pytrends.pytrends.request import TrendReq\n",
    "pytrend = TrendReq()\n",
    "\n",
    "timeframe = \"2019-06-5 2019-06-20\"\n",
    "pytrend.build_payload(kw_list=[' '], geo='US', timeframe=timeframe)\n",
    "topics_df = pytrend.related_top_topics_by_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search topics</th>\n",
       "      <th>Top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019 - Topic</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weather - Topic</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook - Social networking service</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook, Inc. - Social network company</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Search - Topic</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Google - Technology company</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YouTube - Video sharing company</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Film - Topic</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Car - Transportation mode</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texas - US State</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sales - Topic</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon.com - E-commerce company</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>California - US State</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Florida - US State</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Craigslist, Inc. - Advertising company</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Definition - Topic</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Restaurant - Topic</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>City - Topic</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.com - Top level domain</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Food - Food</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>United States - Religious jurisdiction</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lyrics - Topic</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dog - Animal</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pornhub - Internet site</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Walmart - Retail company</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Search topics  Top\n",
       "0                              2019 - Topic  100\n",
       "1                           Weather - Topic   85\n",
       "2      Facebook - Social networking service   73\n",
       "3   Facebook, Inc. - Social network company   73\n",
       "4                     Google Search - Topic   69\n",
       "5               Google - Technology company   67\n",
       "6           YouTube - Video sharing company   64\n",
       "7                              Film - Topic   60\n",
       "8                 Car - Transportation mode   47\n",
       "9                          Texas - US State   46\n",
       "10                            Sales - Topic   46\n",
       "11          Amazon.com - E-commerce company   45\n",
       "12                    California - US State   41\n",
       "13                       Florida - US State   37\n",
       "14   Craigslist, Inc. - Advertising company   36\n",
       "15                       Definition - Topic   36\n",
       "16                       Restaurant - Topic   35\n",
       "17                             City - Topic   35\n",
       "18                  .com - Top level domain   35\n",
       "19                              Food - Food   34\n",
       "20   United States - Religious jurisdiction   34\n",
       "21                           Lyrics - Topic   34\n",
       "22                             Dog - Animal   33\n",
       "23                  Pornhub - Internet site   33\n",
       "24                 Walmart - Retail company   33"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
