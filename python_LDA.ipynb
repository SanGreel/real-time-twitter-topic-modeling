{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_frame = pd.read_csv('../get-tweets-geolocation/src/training_tweets_for_EDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweets_LDA():\n",
    "    \n",
    "    '''\n",
    "    Class gets as input raw-data from twitter in csv format.\n",
    "    There realized methods for data preprocessing and perfoming LDA on the preprocessed data.\n",
    "    As output - words that are indicators of particular topic for tweets.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.path_to_file = ''\n",
    "        self.tweets_frame = pd.DataFrame()\n",
    "        \n",
    "    def load_data(self,path_to_file):\n",
    "        self.path_to_file = path_to_file\n",
    "        self.tweets_frame = pd.read_csv(self.path_to_file)\n",
    "        self.tweets_frame = self.tweets_frame[self.tweets_frame['created_at'].map(lambda x: x[:10])=='Sat Jun 01']\n",
    "        \n",
    "        \n",
    "    def data_preprocessing(self):\n",
    "        WPT = nltk.WordPunctTokenizer()\n",
    "        lemmanizer = WordNetLemmatizer()\n",
    "        stop_word_list = nltk.corpus.stopwords.words('english')\n",
    "        \n",
    "        self.tweets_frame['tweets_processed'] =\\\n",
    "                self.tweets_frame['tweet'].map(lambda x: [lemmanizer.lemmatize(y) for y in re.sub(\"[\\d+0-9.‚Ä¶#!'\\\"_?,;/:()‚Äô%*ü§Ø‚Äú‚Äù&üß®$üß®üß°]\", \"\", x.lower()).split() \n",
    "                                         if y not in stop_word_list \n",
    "                                         and y not in ['„Éª„Éª„Éª','','-']\n",
    "                                         and not y.startswith('http')\n",
    "                                         and not y.startswith('@')])\n",
    "        \n",
    "        self.tweets_frame['tweets_processed'] =\\\n",
    "                self.tweets_frame['tweets_processed'].map(lambda x: [y for y in x if len(y)>2])\n",
    "        \n",
    "        self.tweets_frame = self.tweets_frame[self.tweets_frame['tweets_processed'].map(len)>0]\n",
    "        \n",
    "    def LDA(self,n_topics):\n",
    "        \n",
    "        def create_co_occurences_matrix(allowed_words, documents):\n",
    "            word_to_id = dict(zip(allowed_words, range(len(allowed_words))))\n",
    "            documents_as_ids = [np.sort([word_to_id[w] for w in doc if w in word_to_id]).astype('uint32') for doc in documents]\n",
    "            row_ind, col_ind = zip(*itertools.chain(*[[(i, w) for w in doc] for i, doc in enumerate(documents_as_ids)]))\n",
    "            data = np.ones(len(row_ind), dtype='uint32')  # use unsigned int for better memory utilization\n",
    "            max_word_id = max(itertools.chain(*documents_as_ids)) + 1\n",
    "            docs_words_matrix = csr_matrix((data, (row_ind, col_ind)), shape=(len(documents_as_ids), max_word_id))  # efficient arithmetic operations with CSR * CSR\n",
    "            words_cooc_matrix = docs_words_matrix.T * docs_words_matrix  # multiplying docs_words_matrix with its transpose matrix would generate the co-occurences matrix\n",
    "            words_cooc_matrix.setdiag(0)\n",
    "            return words_cooc_matrix, word_to_id \n",
    "        \n",
    "        def print_topics(model, count_vectorizer, n_top_words,words):\n",
    "            #words = cross_tab.columns\n",
    "            for topic_idx, topic in enumerate(model.components_):\n",
    "                print(\"\\nTopic #%d:\" % topic_idx)\n",
    "                print(\" \".join([words[i]\n",
    "                                for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "        merged = list(itertools.chain.from_iterable(self.tweets_frame['tweets_processed'].values))\n",
    "        merged_cnts = np.unique(merged,return_counts=True)\n",
    "        words = merged_cnts[0][merged_cnts[1]>2]\n",
    "        a, b = create_co_occurences_matrix(words,self.tweets_frame['tweets_processed'].values)\n",
    "        lda_ = LDA(n_components=n_topics)\n",
    "        lda_.fit(a)\n",
    "        print_topics(lda_,' ',60,words)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tweets_LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.load_data('../get-tweets-geolocation/src/training_tweets_for_EDA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "traffic back yankee lane blocked stop min near driver delay accident ave game bike red may june ball win queen sox manhattan final stadium right pkwy liverpool two community stopped america champion blvd left approaching league mets bill team lead run uclfinal park show get tonight one amp hbo state sayin tit first claiming vehicle nyc baseball today board unofficial\n",
      "\n",
      "Topic #1:\n",
      "incident cleared construction avenue street updated station exit direction boulevard qbus road archer new sutphin line queen parkway expressway east closure plaza jersey south level york bridge ave cortelyou north rte event west toll georgewashingtonbridge park island special central bound hill inysthruway ocean washington side belt ramp bbus downtown route flushing bmbus county center interchange bronx mbus richmond penn sideupper\n",
      "\n",
      "Topic #2:\n",
      "new york nyc happy pride today amp month tonight day photo city brooklyn posted jersey park june saturday time chance love sat t-storm jun forecast birthday night sunday summer newyork square manhattan morning freeship weekend center one case beautiful great queen good garden come pridemonth street party world tomorrow may island music year see first event art side mostly open\n",
      "\n",
      "Topic #3:\n",
      "job like link see bio click apply latest opening newyork hiring great want work amp team looking new youre follow dont trump via join fit time career open retail including manager service anyone could title read look day robert score sale view hear might detail store recommend people support every interested system check stop group president health york get even\n",
      "\n",
      "Topic #4:\n",
      "like get dont one time know amp people love day good got really cant make see today year shit need would think never lol thats new going say want still back life ive thing much right even look first way let last great come youre take man always best yall night friend ever feel work every guy show happy thank\n"
     ]
    }
   ],
   "source": [
    "a.LDA(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "day night time amp today last get one new year great first game like good yankee tonight got nyc see come love back summer going home morning let two week best saturday month happy red next weekend take york way every june show make music friend tomorrow win ive play run work team cant girl still watch start season high\n",
      "\n",
      "Topic #1:\n",
      "like dont get one people know time love really cant shit amp make see got day good need lol think never would thats want say life new even thing today still year much ive going right look yall back youre always way man let feel take ever come work friend best guy first someone nigga great happy every lmao better\n",
      "\n",
      "Topic #2:\n",
      "case freeship liverpool champion final movie amp uclfinal league one state clear win watching team fan time dvd white get watch today record like best sleeve would match year see make whentheyseeus american generic john color day black let school watched love jewel come many plastic game double full medium paper boy episode well dont single ynwa cant way great\n",
      "\n",
      "Topic #3:\n",
      "like trump know people amp follow president time dont every job stop day title office would gun look think need want message dems new robert career one text say sound get law ball clock view muellers democrat deleted staring doesnt lisa right barr show american tax country many take please make youre gop hear plan even mueller support vote republican\n",
      "\n",
      "Topic #4:\n",
      "driver near amp june bike may good community lane blocked manhattan one like get god queen love day people board happy today new great dont parked would world right know nyc reported morning saturday illegally thank say make time year life need going back really also family used toyota well friend ave thats park party ice car blvd come way\n",
      "\n",
      "Topic #5:\n",
      "photo posted park new amp nyc york brooklyn garden center king today bookcon show day central prospect jersey cbd love thanks state great square sunset color drinking may book see beautiful booth light studio come good story county city thank hospital world ruiz lefferts company got video queen amazing get joshua anthony time bronx concert honoring expo event trade amc\n",
      "\n",
      "Topic #6:\n",
      "incident cleared construction avenue street updated station exit direction boulevard qbus road archer sutphin line new queen parkway expressway east closure plaza south bridge ave jersey level event cortelyou west rte york north toll island park special central georgewashingtonbridge county bound hill side inysthruway washington ocean belt ramp downtown bbus route flushing bmbus center bronx interchange richmond mbus bxbus gowanus\n",
      "\n",
      "Topic #7:\n",
      "pride happy traffic month back stop delay min accident ave lane blocked june pridemonth birthday music day love food amp pkwy üè≥Ô∏è‚Äçüåà stopped hookah nyc right stonewall approaching celebrate one year valet sugardaddysfridays djfrankswift lgbtq queen today gay vehicle new left sexyentertainers due world brooklyn nycnightlife anniversary community belt two blvd come lie time everyone height disabled let closed beach\n",
      "\n",
      "Topic #8:\n",
      "job link bio like click see apply latest opening hiring newyork great work looking team want youre fit join retail new including via open amp manager service dont anyone score sale recommend detail might follow read store could career interested group check time accounting york teammate currently look health rochester senior hear tip shy opportunity half landing nurse robert system\n",
      "\n",
      "Topic #9:\n",
      "new york nyc tonight city jersey today chance t-storm sat jun forecast brooklyn photo sunday time newyork posted day saturday manhattan love mostly sunny park amp side newyorkcity art america square june summer bill island fashion level happy hbo sayin show tit claiming music unofficial realtime one center readthatagain üë¨üë´üë≠ maher cloudy street party good west like tap open free\n"
     ]
    }
   ],
   "source": [
    "a.LDA(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
