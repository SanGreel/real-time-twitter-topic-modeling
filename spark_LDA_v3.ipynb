{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext, Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector, Vectors, VectorUDT,SparseVector\n",
    "\n",
    "from pyspark.mllib.feature import Word2Vec, IDF, HashingTF\n",
    "from pyspark.mllib.linalg import Vector, Vectors, VectorUDT,SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically spark\n",
    "import pyspark\n",
    "import operator\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "from pyspark.sql.functions import udf, row_number,column\n",
    "\n",
    "# processing\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#staff for LDA\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vector as oldVector, Vectors as oldVectors\n",
    "from pyspark.ml.linalg import Vector as newVector, Vectors as newVectors\n",
    "\n",
    "#for debug purpose only\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "from pyspark.ml.feature import CountVectorizer,StopWordsRemover, HashingTF, IDF, Tokenizer\n",
    "\n",
    "#staff for LDA\n",
    "from pyspark.mllib.linalg import Vector as oldVector, Vectors as oldVectors\n",
    "from pyspark.ml.linalg import Vector as newVector, Vectors as newVectors\n",
    "\n",
    "#for debug purpose only\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_to_show = 20\n",
    "text_file = 'data/listings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(text_file, inferSchema=True, header=True)\n",
    "df = df.select(\"id\", \"name\").dropna(subset=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 22:47:48\n",
      "07042019 22:47:48\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"name\", outputCol=\"words\")\n",
    "df = tokenizer.transform(df)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 22:47:49\n",
      "07042019 22:47:50\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"raw_features\", vocabSize=5000, minDF=2.0)\n",
    "cvmodel = cv.fit(df)\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 22:47:50\n",
      "07042019 22:47:50\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "df = cvmodel.transform(df)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------+\n",
      "|id   |name                                             |words                                                    |raw_features                                                        |\n",
      "+-----+-------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------+\n",
      "|2818 |Quiet Garden View Room & Super Fast WiFi         |[quiet, garden, view, room, &, super, fast, wifi]        |(2674,[8,9,17,31,51,141,237,1189],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|20168|100%Centre-Studio 1 Private Floor/Bathroom       |[100%centre-studio, 1, private, floor/bathroom]          |(2674,[20,103,2583,2615],[1.0,1.0,1.0,1.0])                         |\n",
      "|25428|Lovely apt in City Centre (Jordaan)              |[lovely, apt, in, city, centre, (jordaan)]               |(2674,[1,6,11,25,32,489],[1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|27886|Romantic, stylish B&B houseboat in canal district|[romantic,, stylish, b&b, houseboat, in, canal, district]|(2674,[1,22,52,67,111,134,802],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |\n",
      "|28658|Cosy guest room near city centre -1              |[cosy, guest, room, near, city, centre, -1]              |(2674,[6,8,10,11,15,301],[1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|28871|Comfortable double room                          |[comfortable, double, room]                              |(2674,[8,57,105],[1.0,1.0,1.0])                                     |\n",
      "|29051|Comfortable single room                          |[comfortable, single, room]                              |(2674,[8,57,308],[1.0,1.0,1.0])                                     |\n",
      "|31080|2-story apartment + rooftop terrace              |[2-story, apartment, +, rooftop, terrace]                |(2674,[0,45,53,85,1168],[1.0,1.0,1.0,1.0,1.0])                      |\n",
      "|38266|Nice and quiet place in the Jordaan              |[nice, and, quiet, place, in, the, jordaan]              |(2674,[1,4,7,42,48,51,84],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|41125|Amsterdam Center Entire Apartment                |[amsterdam, center, entire, apartment]                   |(2674,[0,2,14,243],[1.0,1.0,1.0,1.0])                               |\n",
      "+-----+-------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().orderBy(column(\"id\"))\n",
    "df = df.withColumn(\"id\", row_number().over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = df.rdd.map(lambda x: (x[0], x[1], oldVectors.fromML(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ['27987182'], SparseVector(2674, {})),\n",
       " (2, ['21686664'], SparseVector(2674, {2292: 1.0})),\n",
       " (3, ['21686664'], SparseVector(2674, {2292: 1.0})),\n",
       " (4, ['17607060'], SparseVector(2674, {})),\n",
       " (5, ['5630387'], SparseVector(2674, {})),\n",
       " (6,\n",
       "  ['yays', 'bickersgracht', '2-bedroom', 'c'],\n",
       "  SparseVector(2674, {265: 1.0, 693: 1.0, 770: 1.0, 952: 1.0})),\n",
       " (7,\n",
       "  ['yays', 'bickersgracht', '2-bedroom', 'e'],\n",
       "  SparseVector(2674, {265: 1.0, 693: 1.0, 952: 1.0, 1080: 1.0})),\n",
       " (8,\n",
       "  ['roof', 'terrace', 'cozy', 'place'],\n",
       "  SparseVector(2674, {16: 1.0, 45: 1.0, 62: 1.0, 84: 1.0})),\n",
       " (9,\n",
       "  ['amazing', 'apt', 'next', 'to', 'rembrandtpark', '&close', 'to', 'center'],\n",
       "  SparseVector(2674, {13: 2.0, 14: 1.0, 32: 1.0, 58: 1.0, 72: 1.0, 334: 1.0})),\n",
       " (10,\n",
       "  ['yays', 'oostenburgergracht', 'studio', 'a'],\n",
       "  SparseVector(2674, {26: 1.0, 28: 1.0, 693: 1.0, 722: 1.0}))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| _1|                  _2|                  _3|\n",
      "+---+--------------------+--------------------+\n",
      "|  1|          [27987182]|        (2674,[],[])|\n",
      "|  2|          [21686664]| (2674,[2292],[1.0])|\n",
      "|  3|          [21686664]| (2674,[2292],[1.0])|\n",
      "|  4|          [17607060]|        (2674,[],[])|\n",
      "|  5|           [5630387]|        (2674,[],[])|\n",
      "|  6|[yays, bickersgra...|(2674,[265,693,77...|\n",
      "|  7|[yays, bickersgra...|(2674,[265,693,95...|\n",
      "|  8|[roof, terrace, c...|(2674,[16,45,62,8...|\n",
      "|  9|[amazing, apt, ne...|(2674,[13,14,32,5...|\n",
      "| 10|[yays, oostenburg...|(2674,[26,28,693,...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs.toDF().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 22:18:18\n",
      "07042019 22:18:33\n"
     ]
    }
   ],
   "source": [
    "# Run the LDA Topic Modeler\n",
    "# Note the time before and after is printed in order to find out how much time it takes to process x number of records\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "num_topics = 5\n",
    "max_iterations = 20\n",
    "\n",
    "lda_model = LDA.train(rs_df['index', 'raw_features'].rdd.map(list), k=3, maxIterations=max_iterations)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  _1|                  _2|\n",
      "+--------------------+--------------------+\n",
      "|[0, 1, 2, 3, 4, 6...|[0.06455992319820...|\n",
      "|[0, 1, 2, 3, 4, 5...|[0.06395919915980...|\n",
      "|[0, 1, 2, 3, 4, 5...|[0.06382422394248...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topicIndices.toDF().show(10,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b8b8590a6f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopicsMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# vocabArray = lda_model.vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocabArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwordNumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m  \u001b[0;31m# number of words per topic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_model' is not defined"
     ]
    }
   ],
   "source": [
    "topics = lda_model.topicsMatrix()\n",
    "vocabArray = cvmodel.vocabulary\n",
    "\n",
    "wordNumbers = 20  # number of words per topic\n",
    "topicIndices = sc.parallelize(lda_model.describeTopics(maxTermsPerTopic = wordNumbers))\n",
    "\n",
    "def topic_render(topic):  # specify vector id of words to actual words\n",
    "    terms = topic[0]\n",
    "    prob = topic[1]\n",
    "    \n",
    "    result = []\n",
    "    for i in range(wordNumbers):\n",
    "        term = vocabArray[terms[i]]+\":  \"+str(round(prob[i],3))\n",
    "        result.append(term)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "topics_final = topicIndices.map(lambda topic:topic_render(topic)).collect()\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in range(len(topics_final)):\n",
    "    print (\"Topic #\" + str(topic+1) + \"\")\n",
    "    for term in topics_final[topic]:\n",
    "        print (term)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
