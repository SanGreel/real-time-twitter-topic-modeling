{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "from pyspark.sql.functions import udf, row_number,column\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector, Vectors, VectorUDT,SparseVector\n",
    "from pyspark.ml.feature import CountVectorizer,StopWordsRemover, HashingTF, IDF, Tokenizer\n",
    "\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.feature import Word2Vec, IDF, HashingTF\n",
    "from pyspark.mllib.linalg import Vector, Vectors, VectorUDT,SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-29-186.us-east-2.compute.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_to_show = 20\n",
    "text_file = 'data/listings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(text_file, inferSchema=True, header=True)\n",
    "corpus = df.select(\"id\", \"name\").dropna(subset=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"name\", outputCol=\"words\")\n",
    "docDF = tokenizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vector = CountVectorizer(inputCol=\"words\", outputCol=\"vectors\", minDF=5.0)\n",
    "model = Vector.fit(docDF)\n",
    "result = model.transform(docDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------+\n",
      "|id   |name                                             |words                                                    |vectors                                                             |\n",
      "+-----+-------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------+\n",
      "|2818 |Quiet Garden View Room & Super Fast WiFi         |[quiet, garden, view, room, &, super, fast, wifi]        |(1196,[8,9,17,31,51,141,237,1167],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|20168|100%Centre-Studio 1 Private Floor/Bathroom       |[100%centre-studio, 1, private, floor/bathroom]          |(1196,[20,103],[1.0,1.0])                                           |\n",
      "|25428|Lovely apt in City Centre (Jordaan)              |[lovely, apt, in, city, centre, (jordaan)]               |(1196,[1,6,11,25,32,491],[1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|27886|Romantic, stylish B&B houseboat in canal district|[romantic,, stylish, b&b, houseboat, in, canal, district]|(1196,[1,22,52,67,111,134,811],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])       |\n",
      "|28658|Cosy guest room near city centre -1              |[cosy, guest, room, near, city, centre, -1]              |(1196,[6,8,10,11,15,302],[1.0,1.0,1.0,1.0,1.0,1.0])                 |\n",
      "|28871|Comfortable double room                          |[comfortable, double, room]                              |(1196,[8,57,105],[1.0,1.0,1.0])                                     |\n",
      "|29051|Comfortable single room                          |[comfortable, single, room]                              |(1196,[8,57,309],[1.0,1.0,1.0])                                     |\n",
      "|31080|2-story apartment + rooftop terrace              |[2-story, apartment, +, rooftop, terrace]                |(1196,[0,45,53,85,1157],[1.0,1.0,1.0,1.0,1.0])                      |\n",
      "|38266|Nice and quiet place in the Jordaan              |[nice, and, quiet, place, in, the, jordaan]              |(1196,[1,4,7,42,48,51,84],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])            |\n",
      "|41125|Amsterdam Center Entire Apartment                |[amsterdam, center, entire, apartment]                   |(1196,[0,2,14,243],[1.0,1.0,1.0,1.0])                               |\n",
      "+-----+-------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_vectors(e):\n",
    "    a = list(e.indices) # [0:4]\n",
    "    return Vectors.dense(a) # str(type(e.values)) str(a)#\n",
    "\n",
    "def vector_length(l):\n",
    "    return len(l)\n",
    "\n",
    "# my_udf = udf(my_udf_map, StringType())\n",
    "# my_udf = udf(my_udf_map, ArrayType(FloatType()))\n",
    "\n",
    "my_udf = udf(get_words_vectors, VectorUDT())\n",
    "count_vector_len = udf(vector_length, IntegerType())\n",
    "\n",
    "\n",
    "result2 = result.withColumn('vectors2', my_udf(result.vectors))\n",
    "result2 = result2.withColumn('v_len', count_vector_len(result2.vectors2))\n",
    "result2 = result2.filter(result2['v_len'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------+-----+\n",
      "|id   |vectors2                                   |v_len|\n",
      "+-----+-------------------------------------------+-----+\n",
      "|2818 |[8.0,9.0,17.0,31.0,51.0,141.0,237.0,1167.0]|8    |\n",
      "|20168|[20.0,103.0]                               |2    |\n",
      "|25428|[1.0,6.0,11.0,25.0,32.0,491.0]             |6    |\n",
      "|27886|[1.0,22.0,52.0,67.0,111.0,134.0,811.0]     |7    |\n",
      "|28658|[6.0,8.0,10.0,11.0,15.0,302.0]             |6    |\n",
      "|28871|[8.0,57.0,105.0]                           |3    |\n",
      "|29051|[8.0,57.0,309.0]                           |3    |\n",
      "|31080|[0.0,45.0,53.0,85.0,1157.0]                |5    |\n",
      "|38266|[1.0,4.0,7.0,42.0,48.0,51.0,84.0]          |7    |\n",
      "|41125|[0.0,2.0,14.0,243.0]                       |4    |\n",
      "+-----+-------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2.select(\"id\",\"vectors2\",\"v_len\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().orderBy(column(\"id\"))\n",
    "result3 = result2.withColumn(\"id\", row_number().over(w)).select(\"id\", \"vectors2\").rdd.map(lambda x: [int(x[0]), x[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| _1|                  _2|\n",
      "+---+--------------------+\n",
      "|  1|[265.0,682.0,763....|\n",
      "|  2|[265.0,682.0,970....|\n",
      "|  3|[16.0,45.0,62.0,8...|\n",
      "|  4|[13.0,14.0,32.0,5...|\n",
      "|  5|[26.0,28.0,682.0,...|\n",
      "|  6|[28.0,386.0,682.0...|\n",
      "|  7|[26.0,682.0,733.0...|\n",
      "|  8|[0.0,1.0,28.0,303...|\n",
      "|  9|[1.0,12.0,51.0,10...|\n",
      "| 10|[28.0,265.0,682.0...|\n",
      "| 11|[28.0,386.0,682.0...|\n",
      "| 12|[0.0,4.0,6.0,11.0...|\n",
      "| 13|       [34.0,1175.0]|\n",
      "| 14|[3.0,17.0,29.0,49...|\n",
      "| 15|[2.0,79.0,80.0,14...|\n",
      "| 16|[0.0,1.0,30.0,245.0]|\n",
      "| 17|[0.0,1.0,15.0,150.0]|\n",
      "| 18|[141.0,351.0,596....|\n",
      "| 19|[4.0,6.0,11.0,13....|\n",
      "| 20|[1.0,29.0,30.0,40...|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result3.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result3.toDF().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the LDA model\n",
    "\n",
    "seed=1\n",
    "num_topics = 5\n",
    "max_iterations = 4\n",
    "\n",
    "# num_topics, maxIterations=max_iterations, seed=seed\n",
    "\n",
    "ldaModel = LDA.train(result3, k=num_topics, maxIterations=max_iterations, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 4 words):\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = ldaModel.vocabSize()\n",
    "topics = ldaModel.describeTopics()\n",
    "#topics = ldaModel.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 5, 3, 6],\n",
       " [0.1863323292922061,\n",
       "  0.17667451228557676,\n",
       "  0.15902971201358637,\n",
       "  0.1473319326677002])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "5: 0.195\n",
      "4: 0.192\n",
      "3: 0.166\n",
      "6: 0.153\n",
      "\n",
      "Topic #2:\n",
      "4: 0.186\n",
      "5: 0.177\n",
      "3: 0.159\n",
      "6: 0.147\n",
      "\n",
      "Topic #3:\n",
      "4: 0.198\n",
      "5: 0.188\n",
      "3: 0.169\n",
      "6: 0.138\n",
      "\n",
      "Topic #4:\n",
      "4: 0.203\n",
      "5: 0.19\n",
      "3: 0.154\n",
      "6: 0.15\n",
      "\n",
      "Topic #5:\n",
      "5: 0.193\n",
      "4: 0.189\n",
      "6: 0.153\n",
      "3: 0.149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key,topic in enumerate(topics):\n",
    "    print(\"Topic #\" + str(key+1) + \":\")\n",
    "    \n",
    "    for key2, word in enumerate(topic[0]):\n",
    "        print(str(word),\": \",round(topic[1][key2],3),sep=\"\")\n",
    "    print(\"\")\n",
    "#     for word in range(0, vocab_size):\n",
    "#         print(\" \" + str(topics[word][topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------+---------------------------------------------------------+\n",
      "|id   |name                                             |words                                                    |\n",
      "+-----+-------------------------------------------------+---------------------------------------------------------+\n",
      "|2818 |Quiet Garden View Room & Super Fast WiFi         |[quiet, garden, view, room, &, super, fast, wifi]        |\n",
      "|20168|100%Centre-Studio 1 Private Floor/Bathroom       |[100%centre-studio, 1, private, floor/bathroom]          |\n",
      "|25428|Lovely apt in City Centre (Jordaan)              |[lovely, apt, in, city, centre, (jordaan)]               |\n",
      "|27886|Romantic, stylish B&B houseboat in canal district|[romantic,, stylish, b&b, houseboat, in, canal, district]|\n",
      "|28658|Cosy guest room near city centre -1              |[cosy, guest, room, near, city, centre, -1]              |\n",
      "|28871|Comfortable double room                          |[comfortable, double, room]                              |\n",
      "|29051|Comfortable single room                          |[comfortable, single, room]                              |\n",
      "|31080|2-story apartment + rooftop terrace              |[2-story, apartment, +, rooftop, terrace]                |\n",
      "|38266|Nice and quiet place in the Jordaan              |[nice, and, quiet, place, in, the, jordaan]              |\n",
      "|41125|Amsterdam Center Entire Apartment                |[amsterdam, center, entire, apartment]                   |\n",
      "+-----+-------------------------------------------------+---------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docDF.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "from pyspark.mllib.linalg import Vector as oldVector, Vectors as oldVectors\n",
    "\n",
    "from pyspark.ml.linalg import Vector as newVector, Vectors as newVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 15:56:02\n",
      "07042019 15:56:02\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
    "cvmodel = cv.fit(docDF)\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 15:56:03\n",
      "07042019 15:56:03\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "result_cv = cvmodel.transform(docDF)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|  id|                name|               words|        raw_features|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "|2818|Quiet Garden View...|[quiet, garden, v...|(714,[8,9,17,31,5...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_cv.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cv = result_cv.drop(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = result_cv.rdd.map(lambda x: (x[1], x[0], oldVectors.fromML(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_df = rs.toDF(['tweet_words', 'index', 'raw_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['quiet', 'garden', 'view', 'room', '&', 'super', 'fast', 'wifi'],\n",
       "  '2818',\n",
       "  SparseVector(714, {8: 1.0, 9: 1.0, 17: 1.0, 31: 1.0, 51: 1.0, 141: 1.0, 237: 1.0}))]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|         tweet_words|index|        raw_features|\n",
      "+--------------------+-----+--------------------+\n",
      "|[quiet, garden, v...| 2818|(714,[8,9,17,31,5...|\n",
      "|[100%centre-studi...|20168|(714,[20,103],[1....|\n",
      "|[lovely, apt, in,...|25428|(714,[1,6,11,25,3...|\n",
      "|[romantic,, styli...|27886|(714,[1,22,52,67,...|\n",
      "|[cosy, guest, roo...|28658|(714,[6,8,10,11,1...|\n",
      "|[comfortable, dou...|28871|(714,[8,57,105],[...|\n",
      "|[comfortable, sin...|29051|(714,[8,57,309],[...|\n",
      "|[2-story, apartme...|31080|(714,[0,45,53,85]...|\n",
      "|[nice, and, quiet...|38266|(714,[1,4,7,42,48...|\n",
      "|[amsterdam, cente...|41125|(714,[0,2,14,242]...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().orderBy(column(\"index\"))\n",
    "\n",
    "rs_df = rs_df.withColumn(\"index\", row_number().over(w))\n",
    "#.select(\"tweet_words\", \"index\", \"raw_features\")\n",
    "#.rdd.map(lambda x: [x[0], int(x[1]), x[2]])\n",
    "\n",
    "\n",
    "#rs_df = rs_df.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|         tweet_words|index|        raw_features|\n",
      "+--------------------+-----+--------------------+\n",
      "|          [27987182]|    1|         (714,[],[])|\n",
      "|          [21686664]|    2|         (714,[],[])|\n",
      "|          [21686664]|    3|         (714,[],[])|\n",
      "|          [17607060]|    4|         (714,[],[])|\n",
      "|           [5630387]|    5|         (714,[],[])|\n",
      "|[yays, bickersgra...|    6|(714,[265,697],[1...|\n",
      "|[yays, bickersgra...|    7|(714,[265,697],[1...|\n",
      "|[roof, terrace, c...|    8|(714,[16,45,62,84...|\n",
      "|[amazing, apt, ne...|    9|(714,[13,14,32,58...|\n",
      "|[yays, oostenburg...|   10|(714,[26,28,697],...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 15:56:36\n",
      "07042019 15:56:37\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 15:56:38\n",
      "07042019 15:56:51\n"
     ]
    }
   ],
   "source": [
    "# Run the LDA Topic Modeler\n",
    "\n",
    "# Note the time before and after is printed in order to find out how much time it takes to process x number of records\n",
    "\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "num_topics = 10\n",
    "max_iterations = 20\n",
    "lda_model = LDA.train(rs_df['index', 'raw_features'].rdd.map(list), k=num_topics, maxIterations=max_iterations)\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabArray = cvmodel.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordNumbers = 20\n",
    "topicIndices = sc.parallelize(lda_model.describeTopics(maxTermsPerTopic = wordNumbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_render(topic):\n",
    "    terms = topic[0]\n",
    "    result = []\n",
    "    for i in range(wordNumbers):\n",
    "        term = vocabArray[terms[i]]\n",
    "        result.append(term)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07042019 15:57:24\n",
      "07042019 15:57:24\n"
     ]
    }
   ],
   "source": [
    "print(time.strftime('%m%d%Y %H:%M:%S'))\n",
    "topics_final = topicIndices.map(lambda topic:\n",
    "                               topic_render(topic)).collect()\n",
    "print(time.strftime('%m%d%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic0:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "room\n",
      "near\n",
      "&\n",
      "centre\n",
      "house\n",
      "to\n",
      "cosy\n",
      "center\n",
      "garden\n",
      "cozy\n",
      "modern\n",
      "of\n",
      "\n",
      "\n",
      "Topic1:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "&\n",
      "room\n",
      "near\n",
      "centre\n",
      "house\n",
      "to\n",
      "center\n",
      "cosy\n",
      "cozy\n",
      "garden\n",
      "of\n",
      "private\n",
      "\n",
      "\n",
      "Topic2:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "&\n",
      "near\n",
      "room\n",
      "centre\n",
      "house\n",
      "to\n",
      "cosy\n",
      "center\n",
      "cozy\n",
      "of\n",
      "garden\n",
      "modern\n",
      "\n",
      "\n",
      "Topic3:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "room\n",
      "near\n",
      "&\n",
      "centre\n",
      "house\n",
      "to\n",
      "center\n",
      "cosy\n",
      "cozy\n",
      "garden\n",
      "of\n",
      "modern\n",
      "\n",
      "\n",
      "Topic4:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "room\n",
      "&\n",
      "centre\n",
      "near\n",
      "house\n",
      "to\n",
      "center\n",
      "cosy\n",
      "cozy\n",
      "garden\n",
      "of\n",
      "modern\n",
      "\n",
      "\n",
      "Topic5:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "&\n",
      "room\n",
      "near\n",
      "centre\n",
      "house\n",
      "to\n",
      "cosy\n",
      "center\n",
      "garden\n",
      "cozy\n",
      "private\n",
      "of\n",
      "\n",
      "\n",
      "Topic6:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "room\n",
      "&\n",
      "near\n",
      "centre\n",
      "house\n",
      "to\n",
      "center\n",
      "garden\n",
      "cozy\n",
      "cosy\n",
      "of\n",
      "modern\n",
      "\n",
      "\n",
      "Topic7:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "near\n",
      "&\n",
      "room\n",
      "centre\n",
      "house\n",
      "to\n",
      "center\n",
      "cosy\n",
      "garden\n",
      "cozy\n",
      "modern\n",
      "private\n",
      "\n",
      "\n",
      "Topic8:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "&\n",
      "room\n",
      "near\n",
      "house\n",
      "centre\n",
      "to\n",
      "cosy\n",
      "center\n",
      "cozy\n",
      "garden\n",
      "of\n",
      "family\n",
      "\n",
      "\n",
      "Topic9:\n",
      "apartment\n",
      "in\n",
      "amsterdam\n",
      "with\n",
      "the\n",
      "spacious\n",
      "city\n",
      "and\n",
      "&\n",
      "room\n",
      "near\n",
      "centre\n",
      "house\n",
      "to\n",
      "center\n",
      "cosy\n",
      "cozy\n",
      "garden\n",
      "modern\n",
      "of\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display topics\n",
    "\n",
    "for topic in range(len(topics_final)):\n",
    "    print(\"Topic\" + str(topic) + \":\")\n",
    "    for term in topics_final[topic]:\n",
    "        print(term)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### below working with floats approach\n",
    "https://stackoverflow.com/questions/42051184/latent-dirichlet-allocation-lda-in-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Load and parse the data\n",
    "data = sc.textFile(\"./sample_lda_data.txt\")\n",
    "parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------+\n",
      "|_1 |_2                                           |\n",
      "+---+---------------------------------------------+\n",
      "|0  |[1.0,2.0,6.0,0.0,2.0,3.0,1.0,1.0,0.0,0.0,3.0]|\n",
      "|1  |[1.0,3.0,0.0,1.0,3.0,0.0,0.0,2.0,0.0,0.0,1.0]|\n",
      "|2  |[1.0,4.0,1.0,0.0,0.0,4.0,9.0,0.0,1.0,2.0,0.0]|\n",
      "|3  |[2.0,1.0,0.0,3.0,0.0,0.0,5.0,0.0,2.0,3.0,9.0]|\n",
      "|4  |[3.0,1.0,1.0,9.0,3.0,0.0,2.0,0.0,0.0,1.0,3.0]|\n",
      "|5  |[4.0,2.0,0.0,3.0,4.0,5.0,1.0,1.0,1.0,4.0,0.0]|\n",
      "|6  |[2.0,1.0,0.0,3.0,0.0,0.0,5.0,0.0,2.0,2.0,9.0]|\n",
      "|7  |[1.0,1.0,1.0,9.0,2.0,1.0,2.0,0.0,0.0,1.0,3.0]|\n",
      "|8  |[4.0,4.0,0.0,3.0,4.0,2.0,1.0,3.0,0.0,0.0,0.0]|\n",
      "|9  |[2.0,8.0,2.0,0.0,3.0,0.0,2.0,0.0,2.0,7.0,2.0]|\n",
      "+---+---------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.toDF().show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.toDF().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| _1|                  _2|\n",
      "+---+--------------------+\n",
      "|  0|[1.0,2.0,6.0,0.0,...|\n",
      "|  1|[1.0,3.0,0.0,1.0,...|\n",
      "|  2|[1.0,4.0,1.0,0.0,...|\n",
      "|  3|[2.0,1.0,0.0,3.0,...|\n",
      "|  4|[3.0,1.0,1.0,9.0,...|\n",
      "|  5|[4.0,2.0,0.0,3.0,...|\n",
      "|  6|[2.0,1.0,0.0,3.0,...|\n",
      "|  7|[1.0,1.0,1.0,9.0,...|\n",
      "|  8|[4.0,4.0,0.0,3.0,...|\n",
      "|  9|[2.0,8.0,2.0,0.0,...|\n",
      "+---+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Learned topics (as distributions over vocab of 11 words):\n",
      "Topic 0:\n",
      " 3.4375543252729233\n",
      " 5.627205295421971\n",
      " 5.1071077404596945\n",
      " 28.5811901504307\n",
      " 3.021725594081267\n",
      " 2.8325826294464127\n",
      " 13.268104957996346\n",
      " 0.7738939744618656\n",
      " 2.2705047662424396\n",
      " 4.447564961062405\n",
      " 18.512210539204546\n",
      "Topic 1:\n",
      " 11.516720318003484\n",
      " 11.765497162662928\n",
      " 4.493294264073986\n",
      " 3.1875705472492806\n",
      " 5.7212631071986335\n",
      " 5.806064540980248\n",
      " 13.024024782014733\n",
      " 2.0097314808376345\n",
      " 4.36399447641905\n",
      " 12.462556616039091\n",
      " 11.476154999526333\n",
      "Topic 2:\n",
      " 11.045725356723594\n",
      " 11.6072975419151\n",
      " 2.399597995466321\n",
      " 8.23123930232002\n",
      " 16.2570112987201\n",
      " 13.361352829573338\n",
      " 4.707870259988919\n",
      " 7.2163745447005\n",
      " 1.3655007573385092\n",
      " 7.0898784228985035\n",
      " 3.0116344612691206\n"
     ]
    }
   ],
   "source": [
    "corpus.toDF().show(10)\n",
    "# Cluster the documents into three topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=3)\n",
    "\n",
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"name\", outputCol=\"raw_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsData = tokenizer.transform(result) #corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale = spark._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))\n",
    "\n",
    "StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"raw_words\", outputCol=\"words2\")\n",
    "wordsData = remover.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words2\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=1)\n",
    "idfModel = idf.fit(featurizedData)\n",
    "\n",
    "tfidf = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                                                                                                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(10000,[494,1692,1789,2659,7293,8048,8562,9263],[2.445567235227968,2.8094747144167127,3.6888794541139363,5.2799682278798405,3.247046701834897,5.983267779903803,2.46837734783679,8.083328608786376])|\n",
      "|(10000,[4235,4744,8704,9743],[7.102499355774649,4.745189363091357,2.909063890908317,8.776475789346321])                                                                                             |\n",
      "|(10000,[2184,2707,3009,5495,7228],[6.930649098847989,2.506748391703049,3.2752175788015934,2.2903150004022312,3.0144244065661434])                                                                   |\n",
      "|(10000,[2491,5335,8081,8451,9039,9704],[5.2116489839023625,7.572502985020384,3.7013019741124933,4.857808241199506,3.9945550916137296,2.959364629383116])                                            |\n",
      "|(10000,[494,1345,2707,3322,5495,5974,9807],[2.445567235227968,6.29156913955832,2.506748391703049,2.7449895678888523,2.2903150004022312,2.470200502398305,7.102499355774649])                        |\n",
      "|(10000,[494,3100,9161],[2.445567235227968,4.745189363091357,3.842001856215629])                                                                                                                     |\n",
      "|(10000,[494,4531,9161],[2.445567235227968,6.319740016525016,3.842001856215629])                                                                                                                     |\n",
      "|(10000,[892,1372,1928,5080,5431],[8.083328608786376,0.9940854537588608,3.5069008916639377,4.373829867469703,3.759195952531396])                                                                     |\n",
      "|(10000,[1789,3370,8191,9718],[3.6888794541139363,3.4502190541090423,4.322128493092813,3.561540031737335])                                                                                           |\n",
      "|(10000,[828,1372,1511,7173],[1.582289219814055,0.9940854537588608,6.003887067106539,2.7212542764355874])                                                                                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidf.select(\"features\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics = ldaModel.topicsMatrix()\n",
    "# vocabArray = model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordNumbers = 10  # number of words per topic\n",
    "# topicIndices = sc.parallelize(ldaModel.describeTopics(maxTermsPerTopic = wordNumbers))\n",
    "\n",
    "# def topic_render(topic):  # specify vector id of words to actual words\n",
    "#     terms = topic[0]\n",
    "#     result = []\n",
    "#     for i in range(wordNumbers):\n",
    "#         term = vocabArray[terms[i]]\n",
    "#         result.append(term)\n",
    "#     return result\n",
    "\n",
    "# topics_final = topicIndices.map(lambda topic: topic_render(topic)).collect()\n",
    "\n",
    "# for topic in range(len(topics_final)):\n",
    "#     print (\"Topic\" + str(topic) + \":\")\n",
    "#     for term in topics_final[topic]:\n",
    "#         print (term)\n",
    "#     print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
